apiVersion: v1
kind: Pod
metadata:
  name: mlperf-inference
spec:
  restartPolicy: Never
  containers:
  - name: mlperf-env
    image: quay.io/kvalin/mlperf:v5.1
    imagePullPolicy: Always
    resources:
      requests:
        memory: 32Gi 
    volumeMounts:
    - mountPath: /dev/shm
      name: dshm
    command: [ "/bin/sh", "-c" ]
    args: [ "sleep infinity" ]
  volumes:
  - name: dshm
    emptyDir:
      sizeLimit: 16Gi 
      medium: Memory
